{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('romeo.txt', 'r')  # open romeo.txt in read mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rom = f.read()   # use f.read to read file data and store it in variable rom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(rom[:1000])   # print the first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "romList = rom.split()\n",
    "print(romList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "romText = nltk.Text(romList)\n",
    "romText.concordance('she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rWords = nltk.word_tokenize(rom)\n",
    "rWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rSent = nltk.sent_tokenize(rom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "useless = stopwords + list(string.punctuation)\n",
    "useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag = []\n",
    "for w in rWords:\n",
    "    if w not in useless:\n",
    "        bag.append(w)\n",
    "print(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag = [w for w in rWords if w not in useless]    # one-line code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting text from an html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = urllib.request.urlopen(url).read()    # this was the missing line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup   # BeautifulSoup is a library for cleaning html file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html).get_text()\n",
    "raw[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Reviews Dataset\n",
    "NLTK corpus with 200 text files, each is a review of a movie.  They are split in a neg folder\n",
    "for the negative reviews and a pos folder for the positive reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download(\"movie_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()   # to download nltk data interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fileids` method provided by all the datasets in `nltk.corpus` gives access to a list of all the files available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_reviews.fileids()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fileids can also filter the available files based on their category, which is the name of the subfolders they are located in. Therefore we can have lists of positive and negative reviews separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_fileids = movie_reviews.fileids('neg')\n",
    "positive_fileids = movie_reviews.fileids('pos')\n",
    "len(negative_fileids), len(positive_fileids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect one of the reviews using the raw method of movie_reviews, each file is split into sentences, the curators of this dataset also removed from each review from any direct mention of the rating of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(movie_reviews.raw(fileids=positive_fileids[0]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie_reviews corpus already has direct access to tokenized text with the words method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_reviews.words(fileids=positive_fileids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = movie_reviews.words()\n",
    "len(all_words)                        # how many words are in the entire movie reviews corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_words = [w for w in movie_reviews.words() if w not in useless] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counter = Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_common_words = word_counter.most_common()[:10]\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_word_counts = sorted(list(word_counter.values()), reverse=True)\n",
    "\n",
    "plt.loglog(sorted_word_counts)\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.xlabel(\"Word Rank\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted_word_counts, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted_word_counts, bins=50, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Classifier for Sentiment Analysis\n",
    "\n",
    "Using our `build_bag_of_words_features` function we can build separately the negative and positive features.\n",
    "Basically for each of the 1000 negative and for the 1000 positive review, we create one dictionary of the words and we associate the label \"neg\" and \"pos\" to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_of_words_filtered(words):\n",
    "    return {\n",
    "        word:1 for word in words \\\n",
    "        if not word in useless}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_features = [\n",
    "    (build_bag_of_words_filtered(movie_reviews.words(fileids=[f])), 'neg') \\\n",
    "    for f in negative_fileids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(negative_features[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_features = [\n",
    "    (build_bag_of_words_filtered(movie_reviews.words(fileids=[f])), 'pos') \\\n",
    "    for f in positive_fileids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(positive_features[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest supervised machine learning classifiers is the Naive Bayes Classifier, we will train it on 80% of the data to learn what words are generally associated with positive or with negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_classifier = NaiveBayesClassifier.train(positive_features[:split]+negative_features[:split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.classify.util.accuracy(sentiment_classifier, positive_features[:split]+negative_features[:split])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy above is mostly a check that nothing went very wrong in the training, the real measure of accuracy is on the remaining 20% of the data that wasn't used in training, the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.classify.util.accuracy(sentiment_classifier, positive_features[split:]+negative_features[split:])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy here is around 70% which is pretty good for such a simple model if we consider that the estimated accuracy for a person is about 80%. We can finally print the most informative features, i.e. the words that mostly identify a positive or a negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('romeo.txt', 'r')  # open romeo.txt in read mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('romeo.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b444ca404ca0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rom' is not defined"
     ]
    }
   ],
   "source": [
    "rom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'romeo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6a474885182e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mromeo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'romeo' is not defined"
     ]
    }
   ],
   "source": [
    "romeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"But, soft! what light through yonder window breaks?\\nIt is the east, and Juliet is the sun.\\nArise, fair sun, and kill the envious moon,\\nWho is already sick and pale with grief,\\nThat thou her maid art far more fair than she:\\nBe not her maid, since she is envious;\\nHer vestal livery is but sick and green\\nAnd none but fools do wear it; cast it off.\\nIt is my lady, O, it is my love!\\nO, that she knew she were!\\nShe speaks yet she says nothing: what of that?\\nHer eye discourses; I will answer it.\\nI am too bold, 'tis not to me she speaks:\\nTwo of the fairest stars in all the heaven,\\nHaving some business, do entreat her eyes\\nTo twinkle in their spheres till they return.\\nWhat if her eyes were there, they in her head?\\nThe brightness of her cheek would shame those stars,\\nAs daylight doth a lamp; her eyes in heaven\\nWould through the airy region stream so bright\\nThat birds would sing and think it were not night.\\nSee, how she leans her cheek upon her hand!\\nO, that I were a glove upon that hand,\\nThat I might touch that cheek!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['But,', 'soft!', 'what', 'light', 'through', 'yonder', 'window', 'breaks?', 'It', 'is', 'the', 'east,', 'and', 'Juliet', 'is', 'the', 'sun.', 'Arise,', 'fair', 'sun,', 'and', 'kill', 'the', 'envious', 'moon,', 'Who', 'is', 'already', 'sick', 'and', 'pale', 'with', 'grief,', 'That', 'thou', 'her', 'maid', 'art', 'far', 'more', 'fair', 'than', 'she:', 'Be', 'not', 'her', 'maid,', 'since', 'she', 'is', 'envious;', 'Her', 'vestal', 'livery', 'is', 'but', 'sick', 'and', 'green', 'And', 'none', 'but', 'fools', 'do', 'wear', 'it;', 'cast', 'it', 'off.', 'It', 'is', 'my', 'lady,', 'O,', 'it', 'is', 'my', 'love!', 'O,', 'that', 'she', 'knew', 'she', 'were!', 'She', 'speaks', 'yet', 'she', 'says', 'nothing:', 'what', 'of', 'that?', 'Her', 'eye', 'discourses;', 'I', 'will', 'answer', 'it.', 'I', 'am', 'too', 'bold,', \"'tis\", 'not', 'to', 'me', 'she', 'speaks:', 'Two', 'of', 'the', 'fairest', 'stars', 'in', 'all', 'the', 'heaven,', 'Having', 'some', 'business,', 'do', 'entreat', 'her', 'eyes', 'To', 'twinkle', 'in', 'their', 'spheres', 'till', 'they', 'return.', 'What', 'if', 'her', 'eyes', 'were', 'there,', 'they', 'in', 'her', 'head?', 'The', 'brightness', 'of', 'her', 'cheek', 'would', 'shame', 'those', 'stars,', 'As', 'daylight', 'doth', 'a', 'lamp;', 'her', 'eyes', 'in', 'heaven', 'Would', 'through', 'the', 'airy', 'region', 'stream', 'so', 'bright', 'That', 'birds', 'would', 'sing', 'and', 'think', 'it', 'were', 'not', 'night.', 'See,', 'how', 'she', 'leans', 'her', 'cheek', 'upon', 'her', 'hand!', 'O,', 'that', 'I', 'were', 'a', 'glove', 'upon', 'that', 'hand,', 'That', 'I', 'might', 'touch', 'that', 'cheek!']\n"
     ]
    }
   ],
   "source": [
    "romList = rom.split()\n",
    "print(romList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 7 of 7 matches:\n",
      "fair than she: Be not her maid, since she is envious; Her vestal livery is but \n",
      "is my lady, O, it is my love! O, that she knew she were! She speaks yet she say\n",
      "y, O, it is my love! O, that she knew she were! She speaks yet she says nothing\n",
      "s my love! O, that she knew she were! She speaks yet she says nothing: what of \n",
      "hat she knew she were! She speaks yet she says nothing: what of that? Her eye d\n",
      "wer it. I am too bold, 'tis not to me she speaks: Two of the fairest stars in a\n",
      "and think it were not night. See, how she leans her cheek upon her hand! O, tha\n"
     ]
    }
   ],
   "source": [
    "romText = nltk.Text(romList)\n",
    "romText.concordance('she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\praja_m3gddx7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But',\n",
       " ',',\n",
       " 'soft',\n",
       " '!',\n",
       " 'what',\n",
       " 'light',\n",
       " 'through',\n",
       " 'yonder',\n",
       " 'window',\n",
       " 'breaks',\n",
       " '?',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'east',\n",
       " ',',\n",
       " 'and',\n",
       " 'Juliet',\n",
       " 'is',\n",
       " 'the',\n",
       " 'sun',\n",
       " '.',\n",
       " 'Arise',\n",
       " ',',\n",
       " 'fair',\n",
       " 'sun',\n",
       " ',',\n",
       " 'and',\n",
       " 'kill',\n",
       " 'the',\n",
       " 'envious',\n",
       " 'moon',\n",
       " ',',\n",
       " 'Who',\n",
       " 'is',\n",
       " 'already',\n",
       " 'sick',\n",
       " 'and',\n",
       " 'pale',\n",
       " 'with',\n",
       " 'grief',\n",
       " ',',\n",
       " 'That',\n",
       " 'thou',\n",
       " 'her',\n",
       " 'maid',\n",
       " 'art',\n",
       " 'far',\n",
       " 'more',\n",
       " 'fair',\n",
       " 'than',\n",
       " 'she',\n",
       " ':',\n",
       " 'Be',\n",
       " 'not',\n",
       " 'her',\n",
       " 'maid',\n",
       " ',',\n",
       " 'since',\n",
       " 'she',\n",
       " 'is',\n",
       " 'envious',\n",
       " ';',\n",
       " 'Her',\n",
       " 'vestal',\n",
       " 'livery',\n",
       " 'is',\n",
       " 'but',\n",
       " 'sick',\n",
       " 'and',\n",
       " 'green',\n",
       " 'And',\n",
       " 'none',\n",
       " 'but',\n",
       " 'fools',\n",
       " 'do',\n",
       " 'wear',\n",
       " 'it',\n",
       " ';',\n",
       " 'cast',\n",
       " 'it',\n",
       " 'off',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'my',\n",
       " 'lady',\n",
       " ',',\n",
       " 'O',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'my',\n",
       " 'love',\n",
       " '!',\n",
       " 'O',\n",
       " ',',\n",
       " 'that',\n",
       " 'she',\n",
       " 'knew',\n",
       " 'she',\n",
       " 'were',\n",
       " '!',\n",
       " 'She',\n",
       " 'speaks',\n",
       " 'yet',\n",
       " 'she',\n",
       " 'says',\n",
       " 'nothing',\n",
       " ':',\n",
       " 'what',\n",
       " 'of',\n",
       " 'that',\n",
       " '?',\n",
       " 'Her',\n",
       " 'eye',\n",
       " 'discourses',\n",
       " ';',\n",
       " 'I',\n",
       " 'will',\n",
       " 'answer',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'too',\n",
       " 'bold',\n",
       " ',',\n",
       " \"'t\",\n",
       " 'is',\n",
       " 'not',\n",
       " 'to',\n",
       " 'me',\n",
       " 'she',\n",
       " 'speaks',\n",
       " ':',\n",
       " 'Two',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fairest',\n",
       " 'stars',\n",
       " 'in',\n",
       " 'all',\n",
       " 'the',\n",
       " 'heaven',\n",
       " ',',\n",
       " 'Having',\n",
       " 'some',\n",
       " 'business',\n",
       " ',',\n",
       " 'do',\n",
       " 'entreat',\n",
       " 'her',\n",
       " 'eyes',\n",
       " 'To',\n",
       " 'twinkle',\n",
       " 'in',\n",
       " 'their',\n",
       " 'spheres',\n",
       " 'till',\n",
       " 'they',\n",
       " 'return',\n",
       " '.',\n",
       " 'What',\n",
       " 'if',\n",
       " 'her',\n",
       " 'eyes',\n",
       " 'were',\n",
       " 'there',\n",
       " ',',\n",
       " 'they',\n",
       " 'in',\n",
       " 'her',\n",
       " 'head',\n",
       " '?',\n",
       " 'The',\n",
       " 'brightness',\n",
       " 'of',\n",
       " 'her',\n",
       " 'cheek',\n",
       " 'would',\n",
       " 'shame',\n",
       " 'those',\n",
       " 'stars',\n",
       " ',',\n",
       " 'As',\n",
       " 'daylight',\n",
       " 'doth',\n",
       " 'a',\n",
       " 'lamp',\n",
       " ';',\n",
       " 'her',\n",
       " 'eyes',\n",
       " 'in',\n",
       " 'heaven',\n",
       " 'Would',\n",
       " 'through',\n",
       " 'the',\n",
       " 'airy',\n",
       " 'region',\n",
       " 'stream',\n",
       " 'so',\n",
       " 'bright',\n",
       " 'That',\n",
       " 'birds',\n",
       " 'would',\n",
       " 'sing',\n",
       " 'and',\n",
       " 'think',\n",
       " 'it',\n",
       " 'were',\n",
       " 'not',\n",
       " 'night',\n",
       " '.',\n",
       " 'See',\n",
       " ',',\n",
       " 'how',\n",
       " 'she',\n",
       " 'leans',\n",
       " 'her',\n",
       " 'cheek',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'hand',\n",
       " '!',\n",
       " 'O',\n",
       " ',',\n",
       " 'that',\n",
       " 'I',\n",
       " 'were',\n",
       " 'a',\n",
       " 'glove',\n",
       " 'upon',\n",
       " 'that',\n",
       " 'hand',\n",
       " ',',\n",
       " 'That',\n",
       " 'I',\n",
       " 'might',\n",
       " 'touch',\n",
       " 'that',\n",
       " 'cheek',\n",
       " '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rWords = nltk.word_tokenize(rom)\n",
    "rWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rSent = nltk.sent_tokenize(rom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\praja_m3gddx7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "useless = stopwords + list(string.punctuation)\n",
    "useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['But', 'soft', 'light', 'yonder', 'window', 'breaks', 'It', 'east', 'Juliet', 'sun', 'Arise', 'fair', 'sun', 'kill', 'envious', 'moon', 'Who', 'already', 'sick', 'pale', 'grief', 'That', 'thou', 'maid', 'art', 'far', 'fair', 'Be', 'maid', 'since', 'envious', 'Her', 'vestal', 'livery', 'sick', 'green', 'And', 'none', 'fools', 'wear', 'cast', 'It', 'lady', 'O', 'love', 'O', 'knew', 'She', 'speaks', 'yet', 'says', 'nothing', 'Her', 'eye', 'discourses', 'I', 'answer', 'I', 'bold', \"'t\", 'speaks', 'Two', 'fairest', 'stars', 'heaven', 'Having', 'business', 'entreat', 'eyes', 'To', 'twinkle', 'spheres', 'till', 'return', 'What', 'eyes', 'head', 'The', 'brightness', 'cheek', 'would', 'shame', 'stars', 'As', 'daylight', 'doth', 'lamp', 'eyes', 'heaven', 'Would', 'airy', 'region', 'stream', 'bright', 'That', 'birds', 'would', 'sing', 'think', 'night', 'See', 'leans', 'cheek', 'upon', 'hand', 'O', 'I', 'glove', 'upon', 'hand', 'That', 'I', 'might', 'touch', 'cheek']\n"
     ]
    }
   ],
   "source": [
    "bag = []\n",
    "for w in rWords:\n",
    "    if w not in useless:\n",
    "        bag.append(w)\n",
    "print(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = [w for w in rWords if w not in useless]    # one-line code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
